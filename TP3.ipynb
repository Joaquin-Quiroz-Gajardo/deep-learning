{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofjF2uJnyZo_",
        "outputId": "34f08f2e-a3d1-4259-9a20-d5fba1dceaa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4241933666698694\n",
            "Model(\n",
            "  (linear1): Linear(in_features=1, out_features=2, bias=True)\n",
            "  (linear2): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n",
            "[2.19525402 2.86075747 2.4110535  2.17953273 1.6946192  2.58357645\n",
            " 1.75034885 3.567092   3.85465104 1.53376608] (10000,)\n",
            "[ 1.88843563  4.21131568  4.36963432  2.34812646  4.74068943  1.70670343\n",
            "  3.46873188  1.54630993 -2.27128319  1.66577917]\n",
            "[1, 10000] loss: 3.753\n",
            "[2, 10000] loss: 3.659\n",
            "[3, 10000] loss: 3.634\n",
            "[4, 10000] loss: 3.628\n",
            "[5, 10000] loss: 3.626\n",
            "[6, 10000] loss: 3.626\n",
            "[7, 10000] loss: 3.625\n",
            "[8, 10000] loss: 3.625\n",
            "[9, 10000] loss: 3.625\n",
            "[10, 10000] loss: 3.625\n",
            "[11, 10000] loss: 3.625\n",
            "[12, 10000] loss: 3.625\n",
            "[13, 10000] loss: 3.624\n",
            "[14, 10000] loss: 3.624\n",
            "[15, 10000] loss: 3.624\n",
            "[16, 10000] loss: 3.624\n",
            "[17, 10000] loss: 3.624\n",
            "[18, 10000] loss: 3.624\n",
            "[19, 10000] loss: 3.624\n",
            "[20, 10000] loss: 3.624\n",
            "[21, 10000] loss: 3.624\n",
            "[22, 10000] loss: 3.624\n",
            "[23, 10000] loss: 3.624\n",
            "[24, 10000] loss: 3.624\n",
            "[25, 10000] loss: 3.624\n",
            "[26, 10000] loss: 3.624\n",
            "[27, 10000] loss: 3.624\n",
            "[28, 10000] loss: 3.624\n",
            "[29, 10000] loss: 3.624\n",
            "[30, 10000] loss: 3.624\n",
            "[31, 10000] loss: 3.624\n",
            "[32, 10000] loss: 3.624\n",
            "[33, 10000] loss: 3.624\n",
            "[34, 10000] loss: 3.624\n",
            "[35, 10000] loss: 3.624\n",
            "[36, 10000] loss: 3.624\n",
            "[37, 10000] loss: 3.624\n",
            "[38, 10000] loss: 3.624\n",
            "[39, 10000] loss: 3.624\n",
            "[40, 10000] loss: 3.624\n",
            "[41, 10000] loss: 3.624\n",
            "[42, 10000] loss: 3.624\n",
            "[43, 10000] loss: 3.624\n",
            "[44, 10000] loss: 3.624\n",
            "[45, 10000] loss: 3.624\n",
            "[46, 10000] loss: 3.624\n",
            "[47, 10000] loss: 3.624\n",
            "[48, 10000] loss: 3.624\n",
            "[49, 10000] loss: 3.624\n",
            "[50, 10000] loss: 3.624\n",
            "[51, 10000] loss: 3.624\n",
            "[52, 10000] loss: 3.624\n",
            "[53, 10000] loss: 3.624\n",
            "[54, 10000] loss: 3.624\n",
            "[55, 10000] loss: 3.624\n",
            "[56, 10000] loss: 3.624\n",
            "[57, 10000] loss: 3.624\n",
            "[58, 10000] loss: 3.624\n",
            "[59, 10000] loss: 3.624\n",
            "[60, 10000] loss: 3.624\n",
            "[61, 10000] loss: 3.624\n",
            "[62, 10000] loss: 3.624\n",
            "[63, 10000] loss: 3.624\n",
            "[64, 10000] loss: 3.624\n",
            "[65, 10000] loss: 3.624\n",
            "[66, 10000] loss: 3.624\n",
            "[67, 10000] loss: 3.624\n",
            "[68, 10000] loss: 3.624\n",
            "[69, 10000] loss: 3.624\n",
            "[70, 10000] loss: 3.624\n",
            "[71, 10000] loss: 3.624\n",
            "[72, 10000] loss: 3.624\n",
            "[73, 10000] loss: 3.624\n",
            "[74, 10000] loss: 3.624\n",
            "[75, 10000] loss: 3.624\n",
            "[76, 10000] loss: 3.624\n",
            "[77, 10000] loss: 3.624\n",
            "[78, 10000] loss: 3.624\n",
            "[79, 10000] loss: 3.624\n",
            "[80, 10000] loss: 3.624\n",
            "[81, 10000] loss: 3.624\n",
            "[82, 10000] loss: 3.624\n",
            "[83, 10000] loss: 3.624\n",
            "[84, 10000] loss: 3.624\n",
            "[85, 10000] loss: 3.624\n",
            "[86, 10000] loss: 3.624\n",
            "[87, 10000] loss: 3.624\n",
            "[88, 10000] loss: 3.624\n",
            "[89, 10000] loss: 3.624\n",
            "[90, 10000] loss: 3.624\n",
            "[91, 10000] loss: 3.624\n",
            "[92, 10000] loss: 3.624\n",
            "[93, 10000] loss: 3.624\n",
            "[94, 10000] loss: 3.624\n",
            "[95, 10000] loss: 3.624\n",
            "[96, 10000] loss: 3.624\n",
            "[97, 10000] loss: 3.624\n",
            "[98, 10000] loss: 3.624\n",
            "[99, 10000] loss: 3.624\n",
            "[100, 10000] loss: 3.624\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def formula(x):\n",
        "    return (-(x-2)**2) + 3 + 2 * np.sin(16* x)\n",
        "\n",
        "print(formula(1))\n",
        "\n",
        "import torch\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()# super(GarmentClassifier, self).__init__()\n",
        "        self.linear1=torch.nn.Linear(1, 2, bias=True)\n",
        "        self.linear2=torch.nn.Linear(2, 1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.linear1(x))\n",
        "        x = torch.sigmoid(self.linear2(x))\n",
        "        return x\n",
        "\n",
        "model = Model()\n",
        "print(model)\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "data_x = np.random.rand(10000) * 4\n",
        "data_y = np.array(list(map(formula, data_x)))\n",
        "\n",
        "print(data_x[:10], data_x.shape)\n",
        "print(data_y[:10])\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "tensor_x = torch.Tensor(data_x) # transform to torch tensor\n",
        "tensor_y = torch.Tensor(data_y)\n",
        "\n",
        "my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "my_dataloader = DataLoader(my_dataset, batch_size=1) # create your dataloader\n",
        "\n",
        "for epoch in range(100):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(my_dataloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # print(loss.item())\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 10000 == 9999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    }
  ]
}